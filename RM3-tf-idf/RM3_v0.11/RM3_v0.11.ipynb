{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dad0912a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f5a0cbaee30>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import lucene\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from java.io import File\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.util import BytesRefIterator\n",
    "from org.apache.lucene.index import DirectoryReader, Term\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.analysis.core import WhitespaceAnalyzer\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher, BooleanQuery, BooleanClause, TermQuery, BoostQuery\n",
    "from org.apache.lucene.search.similarities import BM25Similarity, LMJelinekMercerSimilarity, LMDirichletSimilarity\n",
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daecea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_name = 'trec678-robust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da8c844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = '../../index/'\n",
    "topicFilePath = f'../../{q_name}.xml'\n",
    "\n",
    "directory = FSDirectory.open(File(index_path).toPath())\n",
    "indexReader = DirectoryReader.open(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3061de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_topics(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    parsed_topics = {}\n",
    "\n",
    "    for top in root.findall('top'):\n",
    "        num = top.find('num').text.strip()\n",
    "        title = top.find('title').text.strip()\n",
    "        parsed_topics[num] = title\n",
    "\n",
    "    return parsed_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b64d41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all = query_topics(topicFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64bc6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocumentVector(luceneDocid, indexReader):\n",
    "\n",
    "    N = indexReader.numDocs()                   \n",
    "    \n",
    "    docVec = defaultdict(lambda: [0, 0]) \n",
    "    D = 0                                 \n",
    "    \n",
    "    terms = indexReader.getTermVector(luceneDocid, 'CONTENTS')\n",
    "    iterator = terms.iterator()\n",
    "    for term in BytesRefIterator.cast_(iterator):\n",
    "        t = term.utf8ToString()\n",
    "        tf = iterator.totalTermFreq()  \n",
    "        df = indexReader.docFreq(Term('CONTENTS', t))  \n",
    "        D += tf\n",
    "        docVec[t][0] = tf\n",
    "        docVec[t][1] = df\n",
    "    \n",
    "    docVec = {key: (value[0] / D) * math.log(N / (value[1] + 1)) for key, value in docVec.items()}\n",
    "    \n",
    "    total_weight = sum(docVec.values())\n",
    "    docVec = {key: value / total_weight for key, value in docVec.items()}\n",
    "\n",
    "    # print(len(docVec), \"D\", D)\n",
    "    return docVec, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "040e7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terms = indexReader.getTermVector(1, 'CONTENTS')\n",
    "# terms.getStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "076c7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(indexReader, query, similarity, top_rel_doc):\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    searcher = IndexSearcher(indexReader)\n",
    "    searcher.setSimilarity(similarity)\n",
    "    # query = QueryParser(\"CONTENTS\", analyzer).parse(query)\n",
    "\n",
    "    scoreDocs = searcher.search(query, top_rel_doc).scoreDocs\n",
    "    \n",
    "    docids = [scoreDoc.doc for scoreDoc in scoreDocs]\n",
    "\n",
    "    set_cont = set()\n",
    "    set_cont = {term for doc in docids for term in getDocumentVector(doc, indexReader)[0].keys()}\n",
    "\n",
    "    filtered_tok = set()\n",
    "    for tok in set_cont:\n",
    "        if tok.isalpha():\n",
    "            filtered_tok.add(tok)\n",
    "\n",
    "    # N = indexReader.numDocs()  \n",
    "    # new_set = []\n",
    "    # for t in set_cont:\n",
    "    #     df = indexReader.docFreq(Term('CONTENTS', t)) \n",
    "    #     if df/N < 0.1:\n",
    "    #         new_set.append(t)\n",
    "            \n",
    "    # print('Old Set:', len(set_cont))\n",
    "    # print('New Set:', len(new_set))\n",
    "\n",
    "    # return set_cont, docids\n",
    "    return filtered_tok, docids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33312f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RM3_term_selection(Query, set_ET, docs, indexReader, alpha, mu, expanded_query_terms):\n",
    "    \n",
    "    totalTF = indexReader.getSumTotalTermFreq(\"CONTENTS\")\n",
    "\n",
    "    Q = Query.split()\n",
    "    weight = {}\n",
    "\n",
    "    cf = {}\n",
    "    for t in set_ET | set(Q):\n",
    "        T = Term(\"CONTENTS\", t)\n",
    "        cf[t] = indexReader.totalTermFreq(T)/totalTF\n",
    "\n",
    "    docVectors = {}\n",
    "    mixinglambda = {}\n",
    "    doclength = {}\n",
    "    \n",
    "    for d in docs:                    \n",
    "        docVectors[d], doclength[d] = getDocumentVector(d, indexReader)\n",
    "        \n",
    "    for d in docs:                  \n",
    "        mixinglambda[d] = doclength[d]/(doclength[d] + mu)\n",
    "        \n",
    "    for w in set_ET:\n",
    "        p_wr = 0\n",
    "        for d in docs:                  \n",
    "            ml = mixinglambda[d]\n",
    "            p_wd = (ml*(docVectors[d].get(w,0)) + (1 - ml)*cf[w]) \n",
    "            # p_wd = docVectors[d].get(w,0)     \n",
    "        \n",
    "            p_q = 1\n",
    "            for q in Q:\n",
    "                # p_q = p_q*docVectors[d].get(q,0)   \n",
    "                      \n",
    "                p_q = p_q*(ml*(docVectors[d].get(q,0)) + (1 - ml)*cf[q])   \n",
    "\n",
    "\n",
    "            p_wr = p_wr + p_wd*p_q\n",
    "        weight[w] = p_wr\n",
    "\n",
    "\n",
    "\n",
    "    weight = dict(sorted(weight.items(), key=lambda x:x[1], reverse=True)[:expanded_query_terms])\n",
    "    \n",
    "    norm = sum(weight.values())\n",
    "    if norm == 0:\n",
    "        pass\n",
    "    else:\n",
    "        weight = {w:weight[w]/norm for w in weight}\n",
    "\n",
    "\n",
    " \n",
    "    for w in weight.keys() | set(Q):\n",
    "        weight[w] = (alpha*weight.get(w,0)) + (1-alpha)*(Q.count(w)/len(Q))\n",
    "   \n",
    "\n",
    "    temp_list = sorted(weight.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_weights = dict(temp_list)\n",
    "\n",
    "    return sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bde08540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanded_query_BM25(search, RM3_term_selection, k1, b, alpha, top_rel_doc, expanded_query_terms, mu):\n",
    "\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    similarity = BM25Similarity(k1,b)\n",
    "    expanded_q = []\n",
    "\n",
    "    i = 0\n",
    "    # for q in tqdm(query_all.values(), colour='red', desc='Expanding Queries'):\n",
    "    for q in query_all.values():\n",
    "     \n",
    "        i += 1 \n",
    "        escaped_q = QueryParser('CONTENTS', analyzer).escape(q)      # a few titles had '/' in them which \n",
    "        query = QueryParser('CONTENTS', analyzer).parse(escaped_q)\n",
    "        \n",
    "        query_terms = [term.strip()[9:] for term in query.toString().split()]\n",
    "        parsed_q = ' '.join(query_terms)\n",
    "#         \n",
    "        \n",
    "        # expension_term_set, docids = search(indexReader, parsed_q, similarity, top_rel_doc)\n",
    "        expension_term_set, docids = search(indexReader, query, similarity, top_rel_doc)\n",
    "        weights = RM3_term_selection(parsed_q, expension_term_set, docids, indexReader, alpha, mu, expanded_query_terms)\n",
    "        # print(weights)\n",
    "    \n",
    "        booleanQuery = BooleanQuery.Builder()\n",
    "        for m, n in weights.items():\n",
    "            t = Term('CONTENTS', m)\n",
    "            tq = TermQuery(t)\n",
    "            boostedTermQuery = BoostQuery(tq, float(n))\n",
    "            BooleanQuery.setMaxClauseCount(4096)\n",
    "            booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "        booleanQuery = booleanQuery.build()\n",
    "       \n",
    "        expanded_q.append(booleanQuery)   \n",
    "\n",
    "    return expanded_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "108049ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_retrived(indexReader, Query, Qid, similarity, out_name):\n",
    "\n",
    "    searcher = IndexSearcher(indexReader)\n",
    "    searcher.setSimilarity(similarity)\n",
    "   \n",
    "    scoreDocs = searcher.search(Query, 1000).scoreDocs             #retrieving top 1000 relDoc\n",
    "    i = 1\n",
    "    res = ''\n",
    "\n",
    "    for scoreDoc in scoreDocs:\n",
    "        doc = searcher.doc(scoreDoc.doc)\n",
    "        r = str(Qid) + '\\t' + 'Q0' + '\\t' + str(doc.get('ID')) + '\\t' + str(i) + '\\t' + str(scoreDoc.score) + '\\t' + str(out_name) + '\\n'\n",
    "        res += r\n",
    "        i = i+1   \n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a67596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RM3(top_PRD, expanded_query_terms, alpha, mu):\n",
    "    expand_q = expanded_query_BM25(search, RM3_term_selection, k1, b, alpha, top_PRD, expanded_query_terms, mu)\n",
    "                                       \n",
    "    name = 'prm_'\n",
    "    sim = BM25Similarity(k1,b)\n",
    "    name = name + 'BM25_' + str(k1) + '_'+ str(b)\n",
    "\n",
    "    file_name = f'./res_RM3/{q_name}/{q_name}_mu_' + str(mu) +'_docs_' + str(top_PRD) + '_terms_' + str(expanded_query_terms) + '_alpha_' + str(alpha) + '.txt'\n",
    "    out_file = open(file_name, \"w\")\n",
    "\n",
    "    res = ''\n",
    "    for i in tqdm(range(len(query_all)),colour='cyan', desc = 'Re-retrival'):\n",
    "    # for i in range(len(query_all)):\n",
    "    \n",
    "        result =  search_retrived(indexReader, expand_q[i], list(query_all.keys())[i], sim, name)\n",
    "        res = res + result\n",
    "\n",
    "    out_file.write(res)\n",
    "    out_file.close()\n",
    "    # print(\"Retrieval Completed - result dumped in\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a113aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-retrival: 100%|\u001b[36m██████████\u001b[0m| 250/250 [00:36<00:00,  6.77it/s]\n",
      "Re-retrival: 100%|\u001b[36m██████████\u001b[0m| 250/250 [00:32<00:00,  7.71it/s]\n",
      "100%|\u001b[31m██████████\u001b[0m| 2/2 [14:05<00:00, 422.93s/it]\n"
     ]
    }
   ],
   "source": [
    "k1 = 0.8\n",
    "b = 0.4\n",
    "\n",
    "top_PRD = [50]\n",
    "expanded_query_terms = [25]\n",
    "alpha = [0.7]\n",
    "mu = [125,0]\n",
    "\n",
    "parameters = list(itertools.product(top_PRD, expanded_query_terms, alpha, mu))\n",
    "\n",
    "for num_doc, num_q, alpha, mu in tqdm(parameters, colour='red'):\n",
    "    run_RM3(num_doc, num_q, alpha, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165abd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
