{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dad0912a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f8403539070>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import lucene\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from java.io import File\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.util import BytesRefIterator\n",
    "from org.apache.lucene.index import DirectoryReader, Term\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.analysis.core import WhitespaceAnalyzer\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher, BooleanQuery, BooleanClause, TermQuery, BoostQuery\n",
    "from org.apache.lucene.search.similarities import BM25Similarity, LMJelinekMercerSimilarity, LMDirichletSimilarity\n",
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daecea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_name = 'trec6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da8c844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = '../../index/'\n",
    "topicFilePath = f'../../{q_name}.xml'\n",
    "\n",
    "directory = FSDirectory.open(File(index_path).toPath())\n",
    "indexReader = DirectoryReader.open(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3061de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_topics(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    parsed_topics = {}\n",
    "\n",
    "    for top in root.findall('top'):\n",
    "        num = top.find('num').text.strip()\n",
    "        title = top.find('title').text.strip()\n",
    "        parsed_topics[num] = title\n",
    "\n",
    "    return parsed_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b64d41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all = query_topics(topicFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64bc6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocumentVector(luceneDocid, indexReader):\n",
    "\n",
    "    N = indexReader.numDocs()                   \n",
    "    \n",
    "    docVec = defaultdict(lambda: [0, 0]) \n",
    "    D = 0                                 \n",
    "    \n",
    "    terms = indexReader.getTermVector(luceneDocid, 'CONTENTS')\n",
    "    iterator = terms.iterator()\n",
    "    for term in BytesRefIterator.cast_(iterator):\n",
    "        t = term.utf8ToString()\n",
    "        tf = iterator.totalTermFreq()  \n",
    "        df = indexReader.docFreq(Term('CONTENTS', t))  \n",
    "        D += tf\n",
    "        docVec[t][0] = tf\n",
    "        docVec[t][1] = df\n",
    "    \n",
    "    docVec = {key: (value[0] / D) * math.log(N / (value[1] + 1)) for key, value in docVec.items()}\n",
    "    \n",
    "    total_weight = sum(docVec.values())\n",
    "    docVec = {key: value / total_weight for key, value in docVec.items()}\n",
    "\n",
    "    # print(len(docVec), \"D\", D)\n",
    "    return docVec, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "040e7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terms = indexReader.getTermVector(1, 'CONTENTS')\n",
    "# terms.getStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "076c7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(indexReader, query, similarity, top_rel_doc):\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    searcher = IndexSearcher(indexReader)\n",
    "    searcher.setSimilarity(similarity)\n",
    "    # query = QueryParser(\"CONTENTS\", analyzer).parse(query)\n",
    "\n",
    "    scoreDocs = searcher.search(query, top_rel_doc).scoreDocs\n",
    "    \n",
    "    docids = [scoreDoc.doc for scoreDoc in scoreDocs]\n",
    "\n",
    "    set_cont = set()\n",
    "    set_cont = {term for doc in docids for term in getDocumentVector(doc, indexReader)[0].keys()}\n",
    "\n",
    "    filtered_tok = set()\n",
    "    for tok in set_cont:\n",
    "        if tok.isalpha():\n",
    "            filtered_tok.add(tok)\n",
    "\n",
    "    # N = indexReader.numDocs()  \n",
    "    # new_set = []\n",
    "    # for t in set_cont:\n",
    "    #     df = indexReader.docFreq(Term('CONTENTS', t)) \n",
    "    #     if df/N < 0.1:\n",
    "    #         new_set.append(t)\n",
    "            \n",
    "    # print('Old Set:', len(set_cont))\n",
    "    # print('New Set:', len(new_set))\n",
    "\n",
    "    # return set_cont, docids\n",
    "    return filtered_tok, docids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b873b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RM3_term_selection(Query, set_ET, docs, indexReader, alpha, mu):\n",
    "    \n",
    "#     totalTF = indexReader.getSumTotalTermFreq(\"CONTENTS\")\n",
    "\n",
    "#     Q = Query.split()\n",
    "#     weight = {}\n",
    "\n",
    "#     cf = {}\n",
    "#     for t in set_ET:\n",
    "#         T = Term(\"CONTENTS\", t)\n",
    "#         cf[t] = indexReader.totalTermFreq(T)/totalTF\n",
    "#     for q in Q:\n",
    "#         set_ET.add(q)\n",
    "#         T = Term(\"CONTENTS\", q)\n",
    "#         cf[q] = indexReader.totalTermFreq(T)/totalTF\n",
    "\n",
    "#     docVectors = {}\n",
    "#     mixinglambda = {}\n",
    "#     doclength = {}\n",
    "    \n",
    "#     for d in docs:                    \n",
    "#         docVectors[d], doclength[d] = getDocumentVector(d, indexReader)\n",
    "        \n",
    "#     for d in docs:                  \n",
    "#         mixinglambda[d] = doclength[d]/(doclength[d] + mu)\n",
    "        \n",
    "#     for w in set_ET:\n",
    "#         p_wr = 0\n",
    "#         for d in docs:                  \n",
    "#             ml = mixinglambda[d]\n",
    "#             p_wd = (ml*(docVectors[d].get(w,0)) + (1 - ml)*cf[w])      \n",
    "#             # p_wd = (docVectors[d].get(w,0))      \n",
    "\n",
    "#             p_q = 1\n",
    "#             for q in Q:\n",
    "#                 p_q = p_q*(ml*(docVectors[d].get(q,0)) + (1 - ml)*cf[q])          \n",
    "\n",
    "#             p_wr = p_wr + p_wd*p_q\n",
    "#         weight[w] = p_wr\n",
    "\n",
    "#     norm = sum(weight.values())\n",
    "    \n",
    "#     if norm == 0:\n",
    "#         print(Q,'\\n\\n')\n",
    "#     else:\n",
    "#         weight = {w:weight[w]/norm for w in weight}\n",
    "\n",
    "#     for w in set_ET:\n",
    "#         weight[w] = (alpha*weight[w]) + (1-alpha)*(Q.count(w)/len(Q))\n",
    "\n",
    "#     temp_list = sorted(weight.items(), key=lambda x:x[1], reverse=True)\n",
    "#     sorted_weights = dict(temp_list)\n",
    "\n",
    "#     return sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33312f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RM3_term_selection(Query, set_ET, docs, indexReader, alpha, mu, expanded_query_terms):\n",
    "    \n",
    "    totalTF = indexReader.getSumTotalTermFreq(\"CONTENTS\")\n",
    "\n",
    "    Q = Query.split()\n",
    "    weight = {}\n",
    "\n",
    "    cf = {}\n",
    "    for t in set_ET | set(Q):\n",
    "        T = Term(\"CONTENTS\", t)\n",
    "        cf[t] = indexReader.totalTermFreq(T)/totalTF\n",
    "\n",
    "    docVectors = {}\n",
    "    mixinglambda = {}\n",
    "    doclength = {}\n",
    "    \n",
    "    for d in docs:                    \n",
    "        docVectors[d], doclength[d] = getDocumentVector(d, indexReader)\n",
    "        \n",
    "    for d in docs:                  \n",
    "        mixinglambda[d] = doclength[d]/(doclength[d] + mu)\n",
    "        \n",
    "    for w in set_ET:\n",
    "        p_wr = 0\n",
    "        for d in docs:                  \n",
    "            ml = mixinglambda[d]\n",
    "            # p_wd = (ml*(docVectors[d].get(w,0)) + (1 - ml)*cf[w]) \n",
    "            p_wd = docVectors[d].get(w,0)     \n",
    "        \n",
    "            p_q = 1\n",
    "            for q in Q:\n",
    "                # p_q = p_q*docVectors[d].get(q,0)   \n",
    "                      \n",
    "                p_q = p_q*(ml*(docVectors[d].get(q,0)) + (1 - ml)*cf[q])   \n",
    "\n",
    "\n",
    "            p_wr = p_wr + p_wd*p_q\n",
    "        weight[w] = p_wr\n",
    "\n",
    "\n",
    "\n",
    "    weight = dict(sorted(weight.items(), key=lambda x:x[1], reverse=True)[:expanded_query_terms])\n",
    "    \n",
    "    norm = sum(weight.values())\n",
    "    if norm == 0:\n",
    "        pass\n",
    "    else:\n",
    "        weight = {w:weight[w]/norm for w in weight}\n",
    "\n",
    "\n",
    " \n",
    "    for w in weight.keys() | set(Q):\n",
    "        weight[w] = round((alpha*weight.get(w,0)) + (1-alpha)*(Q.count(w)/len(Q)), 4)\n",
    "   \n",
    "\n",
    "    temp_list = sorted(weight.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_weights = dict(temp_list)\n",
    "\n",
    "    return sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37a65a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expanded_query_BM25(search, RM3_term_selection, k1, b, alpha, top_rel_doc, expanded_query_terms, mu):\n",
    "\n",
    "#     analyzer = EnglishAnalyzer()\n",
    "#     similarity = BM25Similarity(k1,b)\n",
    "#     expanded_q = []\n",
    "\n",
    "#     i = 0\n",
    "#     for q in tqdm(query_all.values(), colour='red', desc='Expanding Queries'):\n",
    "#     # for q in query_all.values():\n",
    "     \n",
    "#         i += 1 \n",
    "#         escaped_q = QueryParser('CONTENTS', analyzer).escape(q)      # a few titles had '/' in them which \n",
    "#         query = QueryParser('CONTENTS', analyzer).parse(escaped_q)\n",
    "        \n",
    "#         query_terms = [term.strip()[9:] for term in query.toString().split()]\n",
    "#         parsed_q = ' '.join(query_terms)\n",
    "# #         print(parsed_q)\n",
    "        \n",
    "#         expension_term_set, docids = search(indexReader, parsed_q, similarity, top_rel_doc)\n",
    "#         # expension_term_set, docids = search(indexReader, query, similarity, top_rel_doc)\n",
    "\n",
    "#         weights = RM3_term_selection(parsed_q, expension_term_set, docids, indexReader, alpha, mu)\n",
    "#         query_len = len(query_terms)\n",
    "#         # query_len = 0\n",
    "        \n",
    "#         expanded_query_terms_list = list(weights.keys())[0:expanded_query_terms + query_len]\n",
    "#         expanded_query_w = list(weights.values())[0:expanded_query_terms + query_len]\n",
    "        \n",
    "#         norm = sum(expanded_query_w)\n",
    "#         expanded_query_weights = list(np.array(expanded_query_w)/norm)\n",
    "    \n",
    "#         booleanQuery = BooleanQuery.Builder()\n",
    "#         for m in range(expanded_query_terms + query_len):\n",
    "#             t = Term('CONTENTS', expanded_query_terms_list[m])\n",
    "#             tq = TermQuery(t)\n",
    "#             boostedTermQuery = BoostQuery(tq, float(expanded_query_weights[m]))\n",
    "#             BooleanQuery.setMaxClauseCount(4096)\n",
    "#             booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "#         booleanQuery = booleanQuery.build()\n",
    "       \n",
    "#         expanded_q.append(booleanQuery)   \n",
    "\n",
    "#     return expanded_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bde08540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def expanded_query_BM25(search, RM3_term_selection, k1, b, alpha, top_rel_doc, expanded_query_terms, mu):\n",
    "\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    similarity = BM25Similarity(k1,b)\n",
    "    expanded_q = []\n",
    "\n",
    "    i = 0\n",
    "    # for q in tqdm(query_all.values(), colour='red', desc='Expanding Queries'):\n",
    "    for q in query_all.values():\n",
    "     \n",
    "        i += 1 \n",
    "        escaped_q = QueryParser('CONTENTS', analyzer).escape(q)      # a few titles had '/' in them which \n",
    "        query = QueryParser('CONTENTS', analyzer).parse(escaped_q)\n",
    "        \n",
    "        query_terms = [term.strip()[9:] for term in query.toString().split()]\n",
    "        parsed_q = ' '.join(query_terms)\n",
    "#         \n",
    "        \n",
    "        # expension_term_set, docids = search(indexReader, parsed_q, similarity, top_rel_doc)\n",
    "        expension_term_set, docids = search(indexReader, query, similarity, top_rel_doc)\n",
    "        weights = RM3_term_selection(parsed_q, expension_term_set, docids, indexReader, alpha, mu, expanded_query_terms)\n",
    "        print(i, q)\n",
    "        pprint.pprint(weights)\n",
    "    \n",
    "        booleanQuery = BooleanQuery.Builder()\n",
    "        for m, n in weights.items():\n",
    "            t = Term('CONTENTS', m)\n",
    "            tq = TermQuery(t)\n",
    "            boostedTermQuery = BoostQuery(tq, float(n))\n",
    "            BooleanQuery.setMaxClauseCount(4096)\n",
    "            booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "        booleanQuery = booleanQuery.build()\n",
    "       \n",
    "        expanded_q.append(booleanQuery)   \n",
    "\n",
    "    return expanded_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "108049ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_retrived(indexReader, Query, Qid, similarity, out_name):\n",
    "\n",
    "    searcher = IndexSearcher(indexReader)\n",
    "    searcher.setSimilarity(similarity)\n",
    "   \n",
    "    scoreDocs = searcher.search(Query, 1000).scoreDocs             #retrieving top 1000 relDoc\n",
    "    i = 1\n",
    "    res = ''\n",
    "\n",
    "    for scoreDoc in scoreDocs:\n",
    "        doc = searcher.doc(scoreDoc.doc)\n",
    "        r = str(Qid) + '\\t' + 'Q0' + '\\t' + str(doc.get('ID')) + '\\t' + str(i) + '\\t' + str(scoreDoc.score) + '\\t' + str(out_name) + '\\n'\n",
    "        res += r\n",
    "        i = i+1   \n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a67596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RM3(top_PRD, expanded_query_terms, alpha, mu):\n",
    "    expand_q = expanded_query_BM25(search, RM3_term_selection, k1, b, alpha, top_PRD, expanded_query_terms, mu)\n",
    "                                       \n",
    "    name = 'prm_'\n",
    "    sim = BM25Similarity(k1,b)\n",
    "    name = name + 'BM25_' + str(k1) + '_'+ str(b)\n",
    "\n",
    "    file_name = f'./res_RM3/{q_name}/{q_name}_mu_' + str(mu) +'_docs_' + str(top_PRD) + '_terms_' + str(expanded_query_terms) + '_alpha_' + str(alpha) + '.txt'\n",
    "    out_file = open(file_name, \"w\")\n",
    "\n",
    "    res = ''\n",
    "    for i in tqdm(range(len(query_all)),colour='cyan', desc = 'Re-retrival'):\n",
    "    # for i in range(len(query_all)):\n",
    "    \n",
    "        result =  search_retrived(indexReader, expand_q[i], list(query_all.keys())[i], sim, name)\n",
    "        res = res + result\n",
    "\n",
    "    out_file.write(res)\n",
    "    out_file.close()\n",
    "    # print(\"Retrieval Completed - result dumped in\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a113aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 International Organized Crime\n",
      "{'affair': 0.0369,\n",
      " 'crime': 0.2914,\n",
      " 'crimin': 0.0801,\n",
      " 'edict': 0.0322,\n",
      " 'feder': 0.065,\n",
      " 'fight': 0.03,\n",
      " 'intern': 0.1329,\n",
      " 'ministri': 0.0355,\n",
      " 'organ': 0.2001,\n",
      " 'russian': 0.0958}\n",
      "2 Poliomyelitis and Post-Polio\n",
      "{'case': 0.0472,\n",
      " 'diseas': 0.0615,\n",
      " 'erad': 0.0322,\n",
      " 'gujarat': 0.0349,\n",
      " 'health': 0.0641,\n",
      " 'hemispher': 0.0444,\n",
      " 'polio': 0.3296,\n",
      " 'poliomyel': 0.1602,\n",
      " 'post': 0.1,\n",
      " 'vaccin': 0.0849,\n",
      " 'viru': 0.0409}\n",
      "3 Hubble Telescope Achievements\n",
      "{'achiev': 0.1,\n",
      " 'flaw': 0.0301,\n",
      " 'hubbl': 0.2434,\n",
      " 'mirror': 0.0752,\n",
      " 'nasa': 0.0658,\n",
      " 'optic': 0.0373,\n",
      " 'shuttl': 0.0257,\n",
      " 'space': 0.0589,\n",
      " 'telescop': 0.2788,\n",
      " 'test': 0.0507,\n",
      " 'truli': 0.0341}\n",
      "4 Endangered Species (Mammals)\n",
      "{'endang': 0.1504,\n",
      " 'fish': 0.0372,\n",
      " 'fisheri': 0.0846,\n",
      " 'incident': 0.055,\n",
      " 'mammal': 0.2467,\n",
      " 'marin': 0.1057,\n",
      " 'nmf': 0.0562,\n",
      " 'permit': 0.033,\n",
      " 'speci': 0.193,\n",
      " 'vessel': 0.0383}\n",
      "5 Most Dangerous Vehicles\n",
      "{'brake': 0.0553,\n",
      " 'danger': 0.1,\n",
      " 'employe': 0.0523,\n",
      " 'fleet': 0.0503,\n",
      " 'machin': 0.0499,\n",
      " 'missil': 0.0476,\n",
      " 'most': 0.1,\n",
      " 'oper': 0.0458,\n",
      " 'shall': 0.0913,\n",
      " 'speed': 0.0759,\n",
      " 'tree': 0.0657,\n",
      " 'vehicl': 0.2659}\n",
      "6 African Civilian Deaths\n",
      "{'african': 0.1897,\n",
      " 'civilian': 0.1546,\n",
      " 'death': 0.2238,\n",
      " 'deathtol': 0.0588,\n",
      " 'forc': 0.046,\n",
      " 'januari': 0.0646,\n",
      " 'rebel': 0.0563,\n",
      " 'rwanda': 0.0989,\n",
      " 'un': 0.0526,\n",
      " 'violenc': 0.0547}\n",
      "7 New Hydroelectric Projects\n",
      "{'capac': 0.041,\n",
      " 'dam': 0.0379,\n",
      " 'electr': 0.0407,\n",
      " 'hydroelectr': 0.3141,\n",
      " 'hyph': 0.0495,\n",
      " 'new': 0.1,\n",
      " 'plant': 0.0384,\n",
      " 'power': 0.0821,\n",
      " 'project': 0.2264,\n",
      " 'river': 0.0321,\n",
      " 'vietnam': 0.0379}\n",
      "8 Implant Dentistry\n",
      "{'antibiot': 0.0374,\n",
      " 'dental': 0.1355,\n",
      " 'dentist': 0.1082,\n",
      " 'dentistri': 0.15,\n",
      " 'dr': 0.0309,\n",
      " 'fda': 0.0382,\n",
      " 'gum': 0.0441,\n",
      " 'implant': 0.3233,\n",
      " 'interpor': 0.0383,\n",
      " 'patient': 0.0622,\n",
      " 'tmj': 0.0318}\n",
      "9 Rap and Crime\n",
      "{'crime': 0.2196,\n",
      " 'gang': 0.0531,\n",
      " 'knott': 0.0605,\n",
      " 'lo': 0.0433,\n",
      " 'music': 0.0656,\n",
      " 'polic': 0.063,\n",
      " 'rap': 0.3411,\n",
      " 'rapper': 0.0596,\n",
      " 'recreat': 0.0408,\n",
      " 'uparr': 0.0534}\n",
      "10 Radio Waves and Brain Cancer\n",
      "{'anxieti': 0.0354,\n",
      " 'brain': 0.1385,\n",
      " 'cancer': 0.1358,\n",
      " 'cellular': 0.1636,\n",
      " 'mccaw': 0.0517,\n",
      " 'motorola': 0.0558,\n",
      " 'phone': 0.0909,\n",
      " 'radio': 0.075,\n",
      " 'reynard': 0.0736,\n",
      " 'scare': 0.0578,\n",
      " 'telephon': 0.047,\n",
      " 'wave': 0.075}\n",
      "11 Industrial Espionage\n",
      "{'aerial': 0.039,\n",
      " 'bnd': 0.0844,\n",
      " 'carratu': 0.0412,\n",
      " 'espionag': 0.4097,\n",
      " 'gm': 0.0409,\n",
      " 'industri': 0.15,\n",
      " 'intellig': 0.048,\n",
      " 'samsung': 0.0358,\n",
      " 'secret': 0.0447,\n",
      " 'spy': 0.0379,\n",
      " 'vw': 0.0685}\n",
      "12 Hydroponics\n",
      "{'bugbe': 0.09,\n",
      " 'drug': 0.0411,\n",
      " 'hydropon': 0.4537,\n",
      " 'marijuana': 0.1118,\n",
      " 'moon': 0.0373,\n",
      " 'plant': 0.0489,\n",
      " 'salisburi': 0.0637,\n",
      " 'sentenc': 0.0378,\n",
      " 'space': 0.0423,\n",
      " 'tomato': 0.0734}\n",
      "13 Magnetic Levitation-Maglev\n",
      "{'car': 0.0392,\n",
      " 'coil': 0.0432,\n",
      " 'levit': 0.152,\n",
      " 'maglev': 0.208,\n",
      " 'magnet': 0.2357,\n",
      " 'nois': 0.0696,\n",
      " 'railwai': 0.0534,\n",
      " 'speed': 0.0482,\n",
      " 'superconduct': 0.1021,\n",
      " 'test': 0.0487}\n",
      "14 Marine Vegetation\n",
      "{'chicken': 0.059,\n",
      " 'cup': 0.0542,\n",
      " 'grill': 0.0589,\n",
      " 'kebab': 0.0607,\n",
      " 'marin': 0.2548,\n",
      " 'oil': 0.0674,\n",
      " 'pepper': 0.0866,\n",
      " 'sauc': 0.0528,\n",
      " 'teaspoon': 0.0529,\n",
      " 'veget': 0.2527}\n",
      "15 Unexplained Highway Accidents\n",
      "{'accid': 0.2017,\n",
      " 'angl': 0.0648,\n",
      " 'driver': 0.0441,\n",
      " 'highwai': 0.1,\n",
      " 'model': 0.0854,\n",
      " 'rollov': 0.0956,\n",
      " 'slide': 0.0466,\n",
      " 'tilt': 0.0731,\n",
      " 'unexplain': 0.1524,\n",
      " 'variabl': 0.0601,\n",
      " 'veloc': 0.0763}\n",
      "16 Polygamy Polyandry Polygyny\n",
      "{'annemari': 0.0712,\n",
      " 'broadcast': 0.0531,\n",
      " 'guildford': 0.057,\n",
      " 'hartlei': 0.0531,\n",
      " 'maguir': 0.1207,\n",
      " 'mavi': 0.0689,\n",
      " 'nepal': 0.0514,\n",
      " 'polyandri': 0.19,\n",
      " 'polygami': 0.1,\n",
      " 'polygyni': 0.1,\n",
      " 'supergrass': 0.0741,\n",
      " 'telltal': 0.0606}\n",
      "17 Unsolicited Faxes\n",
      "{'advertis': 0.035,\n",
      " 'dial': 0.0283,\n",
      " 'fax': 0.3537,\n",
      " 'glynn': 0.028,\n",
      " 'junk': 0.0841,\n",
      " 'legisl': 0.0379,\n",
      " 'machin': 0.0915,\n",
      " 'markei': 0.0294,\n",
      " 'telemarket': 0.0486,\n",
      " 'unsolicit': 0.2635}\n",
      "18 Best Retirement Country\n",
      "{'ag': 0.0391,\n",
      " 'annuiti': 0.1674,\n",
      " 'best': 0.1,\n",
      " 'countri': 0.1,\n",
      " 'judd': 0.0581,\n",
      " 'life': 0.03,\n",
      " 'naomi': 0.0293,\n",
      " 'pension': 0.134,\n",
      " 'retir': 0.2162,\n",
      " 'scheme': 0.0442,\n",
      " 'you': 0.044,\n",
      " 'your': 0.0377}\n",
      "19 New Fuel Sources\n",
      "{'energi': 0.0555,\n",
      " 'fuel': 0.3039,\n",
      " 'japan': 0.0367,\n",
      " 'new': 0.1,\n",
      " 'nonconvent': 0.0424,\n",
      " 'nuclear': 0.0648,\n",
      " 'plant': 0.0366,\n",
      " 'plutonium': 0.0931,\n",
      " 'rokkasho': 0.0415,\n",
      " 'sourc': 0.1886,\n",
      " 'spent': 0.0368}\n",
      "20 Undersea Fiber Optic Cable\n",
      "{'brazil': 0.0494,\n",
      " 'cabl': 0.1443,\n",
      " 'embratel': 0.041,\n",
      " 'fiber': 0.2312,\n",
      " 'optic': 0.2043,\n",
      " 'paulo': 0.0449,\n",
      " 'sao': 0.0495,\n",
      " 'system': 0.0447,\n",
      " 'telecommun': 0.0493,\n",
      " 'undersea': 0.1415}\n",
      "21 Women in Parliaments\n",
      "{'candid': 0.0331,\n",
      " 'communist': 0.035,\n",
      " 'elect': 0.0443,\n",
      " 'femal': 0.0407,\n",
      " 'ginwala': 0.0611,\n",
      " 'mashokw': 0.0348,\n",
      " 'parliament': 0.2383,\n",
      " 'parti': 0.0341,\n",
      " 'polit': 0.037,\n",
      " 'women': 0.4414}\n",
      "22 International Art Crime\n",
      "{'art': 0.2076,\n",
      " 'cartmil': 0.0985,\n",
      " 'crime': 0.2594,\n",
      " 'crimin': 0.0357,\n",
      " 'hubcap': 0.0443,\n",
      " 'intern': 0.1,\n",
      " 'nugent': 0.0324,\n",
      " 'polic': 0.0454,\n",
      " 'stolen': 0.0501,\n",
      " 'stopper': 0.0873,\n",
      " 'wilson': 0.0394}\n",
      "23 Literary/Journalistic Plagiarism\n",
      "{'book': 0.0524,\n",
      " 'coleridg': 0.047,\n",
      " 'hi': 0.0454,\n",
      " 'journalist': 0.1,\n",
      " 'literari': 0.1797,\n",
      " 'mallon': 0.1315,\n",
      " 'plagiar': 0.2053,\n",
      " 'updik': 0.0461,\n",
      " 'whaddidhesai': 0.0435,\n",
      " 'yorker': 0.1056,\n",
      " 'yorkes': 0.0435}\n",
      "24 Argentine/British Relations\n",
      "{'argentin': 0.2159,\n",
      " 'argentina': 0.0934,\n",
      " 'british': 0.1484,\n",
      " 'bueno': 0.0533,\n",
      " 'clarin': 0.0738,\n",
      " 'di': 0.0459,\n",
      " 'falkland': 0.0481,\n",
      " 'island': 0.0503,\n",
      " 'malvina': 0.0708,\n",
      " 'relat': 0.1,\n",
      " 'tella': 0.1003}\n",
      "25 Cult Lifestyles\n",
      "{'cult': 0.2508,\n",
      " 'devote': 0.0399,\n",
      " 'diana': 0.0539,\n",
      " 'greer': 0.1139,\n",
      " 'hare': 0.0476,\n",
      " 'her': 0.076,\n",
      " 'krishna': 0.0757,\n",
      " 'lifestyl': 0.15,\n",
      " 'placentia': 0.0475,\n",
      " 'she': 0.0647,\n",
      " 'trottwel': 0.08}\n",
      "26 Ferry Sinkings\n",
      "{'bow': 0.0527,\n",
      " 'estonia': 0.0944,\n",
      " 'ferri': 0.3498,\n",
      " 'imo': 0.0529,\n",
      " 'maritim': 0.0358,\n",
      " 'roll': 0.0411,\n",
      " 'safeti': 0.0696,\n",
      " 'ship': 0.058,\n",
      " 'sink': 0.2121,\n",
      " 'vessel': 0.0335}\n",
      "27 Modern Slavery\n",
      "{'arvind': 0.0811,\n",
      " 'fogel': 0.0504,\n",
      " 'gandhi': 0.0671,\n",
      " 'india': 0.1063,\n",
      " 'modern': 0.195,\n",
      " 'prof': 0.0448,\n",
      " 'slaveri': 0.2904,\n",
      " 'swadeshi': 0.0631,\n",
      " 'swami': 0.0484,\n",
      " 'vivekananda': 0.0534}\n",
      "28 Pope Beatifications\n",
      "{'beatif': 0.2207,\n",
      " 'beatifi': 0.0465,\n",
      " 'cathol': 0.0403,\n",
      " 'church': 0.0505,\n",
      " 'dei': 0.0337,\n",
      " 'escriva': 0.1288,\n",
      " 'opu': 0.1178,\n",
      " 'pope': 0.2632,\n",
      " 'runci': 0.0319,\n",
      " 'saint': 0.0666}\n",
      "29 Mexican Air Pollution\n",
      "{'air': 0.1415,\n",
      " 'citi': 0.0682,\n",
      " 'environment': 0.0305,\n",
      " 'measur': 0.0302,\n",
      " 'mexican': 0.1704,\n",
      " 'mexico': 0.1753,\n",
      " 'particul': 0.0339,\n",
      " 'pemex': 0.0525,\n",
      " 'pollut': 0.2668,\n",
      " 'salina': 0.0307}\n",
      "30 Iran-Iraq Cooperation\n",
      "{'ankara': 0.0453,\n",
      " 'cooper': 0.1403,\n",
      " 'iran': 0.2552,\n",
      " 'iranian': 0.0498,\n",
      " 'iraq': 0.2252,\n",
      " 'iraqi': 0.0393,\n",
      " 'shihab': 0.0536,\n",
      " 'tehran': 0.0447,\n",
      " 'turkei': 0.1052,\n",
      " 'zarif': 0.0414}\n",
      "31 World Bank Criticism\n",
      "{'bank': 0.2947,\n",
      " 'critic': 0.1556,\n",
      " 'dam': 0.0396,\n",
      " 'imf': 0.076,\n",
      " 'lend': 0.0414,\n",
      " 'loan': 0.0447,\n",
      " 'mors': 0.0435,\n",
      " 'narmada': 0.0561,\n",
      " 'project': 0.0522,\n",
      " 'world': 0.1962}\n",
      "32 Income Tax Evasion\n",
      "{'bolivar': 0.0344,\n",
      " 'deduct': 0.0332,\n",
      " 'enterpris': 0.0277,\n",
      " 'evas': 0.1808,\n",
      " 'incom': 0.2025,\n",
      " 'mainland': 0.0378,\n",
      " 'percent': 0.043,\n",
      " 'rate': 0.0393,\n",
      " 'tax': 0.3627,\n",
      " 'yuan': 0.0386}\n",
      "33 Antibiotics Bacteria Disease\n",
      "{'antibiot': 0.2558,\n",
      " 'bacteria': 0.197,\n",
      " 'diseas': 0.1859,\n",
      " 'henson': 0.0322,\n",
      " 'infect': 0.0893,\n",
      " 'lung': 0.034,\n",
      " 'plagu': 0.0392,\n",
      " 'pneumonia': 0.091,\n",
      " 'resist': 0.0432,\n",
      " 'strep': 0.0324}\n",
      "34 Export Controls Cryptography\n",
      "{'applic': 0.0318,\n",
      " 'comput': 0.0311,\n",
      " 'control': 0.1,\n",
      " 'cryptograph': 0.2444,\n",
      " 'cryptographi': 0.136,\n",
      " 'encrypt': 0.0528,\n",
      " 'export': 0.1,\n",
      " 'fip': 0.0957,\n",
      " 'modul': 0.0603,\n",
      " 'nist': 0.0367,\n",
      " 'pub': 0.0343,\n",
      " 'standard': 0.077}\n",
      "35 Adoptive Biological Parents\n",
      "{'adopt': 0.2222,\n",
      " 'biolog': 0.1449,\n",
      " 'birth': 0.0645,\n",
      " 'child': 0.0688,\n",
      " 'children': 0.0726,\n",
      " 'famili': 0.0479,\n",
      " 'her': 0.0614,\n",
      " 'mother': 0.0522,\n",
      " 'parent': 0.2182,\n",
      " 'she': 0.0472}\n",
      "36 Black Bear Attacks\n",
      "{'anim': 0.0463,\n",
      " 'attack': 0.1436,\n",
      " 'baumruck': 0.0378,\n",
      " 'bear': 0.2394,\n",
      " 'black': 0.1787,\n",
      " 'coverston': 0.1565,\n",
      " 'coyot': 0.0502,\n",
      " 'grizzli': 0.0664,\n",
      " 'he': 0.0356,\n",
      " 'i': 0.0455}\n",
      "37 Viral Hepatitis\n",
      "{'acut': 0.028,\n",
      " 'blood': 0.0324,\n",
      " 'coma': 0.0573,\n",
      " 'diseas': 0.0476,\n",
      " 'hepat': 0.4494,\n",
      " 'infect': 0.0565,\n",
      " 'unspecifi': 0.0273,\n",
      " 'viral': 0.2203,\n",
      " 'viru': 0.0362,\n",
      " 'y': 0.0451}\n",
      "38 Risk of Aspirin\n",
      "{'aspirin': 0.5008,\n",
      " 'attack': 0.0365,\n",
      " 'clot': 0.0314,\n",
      " 'drug': 0.026,\n",
      " 'heart': 0.0493,\n",
      " 'patient': 0.0328,\n",
      " 'risk': 0.1923,\n",
      " 'stroke': 0.0732,\n",
      " 'thrombosi': 0.0321,\n",
      " 'ticlopidin': 0.0256}\n",
      "39 Alzheimer's Drug Treatment\n",
      "{'alzheim': 0.2774,\n",
      " 'brain': 0.0426,\n",
      " 'deprenyl': 0.0583,\n",
      " 'diseas': 0.0677,\n",
      " 'drug': 0.2258,\n",
      " 'hydergin': 0.0467,\n",
      " 'lambert': 0.0371,\n",
      " 'patient': 0.0588,\n",
      " 'studi': 0.0423,\n",
      " 'treatment': 0.1433}\n",
      "40 Land Mine Ban\n",
      "{'antipersonnel': 0.0985,\n",
      " 'ban': 0.2111,\n",
      " 'bumper': 0.028,\n",
      " 'convent': 0.0284,\n",
      " 'drk': 0.0275,\n",
      " 'feder': 0.0268,\n",
      " 'land': 0.1638,\n",
      " 'mine': 0.33,\n",
      " 'moratorium': 0.0485,\n",
      " 'un': 0.0375}\n",
      "41 Airport Security\n",
      "{'air': 0.0354,\n",
      " 'airlin': 0.0471,\n",
      " 'airport': 0.3644,\n",
      " 'aviat': 0.0682,\n",
      " 'baggag': 0.0557,\n",
      " 'carrier': 0.0347,\n",
      " 'faa': 0.0434,\n",
      " 'passeng': 0.0516,\n",
      " 'secur': 0.2644,\n",
      " 'tak': 0.0352}\n",
      "42 Diplomatic Expulsion\n",
      "{'britain': 0.033,\n",
      " 'diplomat': 0.2773,\n",
      " 'embassi': 0.0424,\n",
      " 'expel': 0.0735,\n",
      " 'expuls': 0.3259,\n",
      " 'iran': 0.0466,\n",
      " 'iranian': 0.0539,\n",
      " 'pakhtusov': 0.0467,\n",
      " 'russian': 0.0398,\n",
      " 'soviet': 0.0608}\n",
      "43 Police Deaths\n",
      "{'death': 0.2996,\n",
      " 'di': 0.0354,\n",
      " 'drammen': 0.0371,\n",
      " 'gang': 0.0646,\n",
      " 'investig': 0.0442,\n",
      " 'offic': 0.0451,\n",
      " 'overdos': 0.0405,\n",
      " 'polic': 0.3418,\n",
      " 'said': 0.0385,\n",
      " 'taser': 0.0532}\n",
      "44 Abuses of E-Mail\n",
      "{'abus': 0.1,\n",
      " 'agenc': 0.047,\n",
      " 'e': 0.1965,\n",
      " 'electron': 0.05,\n",
      " 'mail': 0.25,\n",
      " 'messag': 0.0337,\n",
      " 'nara': 0.0877,\n",
      " 'record': 0.0896,\n",
      " 'recordkeep': 0.0488,\n",
      " 'system': 0.0601,\n",
      " 'user': 0.0365}\n",
      "45 Overseas Tobacco Sales\n",
      "{'brand': 0.0364,\n",
      " 'cent': 0.0409,\n",
      " 'cigarett': 0.1119,\n",
      " 'dollar': 0.0518,\n",
      " 'jt': 0.0361,\n",
      " 'nabisco': 0.0426,\n",
      " 'oversea': 0.1,\n",
      " 'rjr': 0.0649,\n",
      " 'sale': 0.1433,\n",
      " 'smoke': 0.0361,\n",
      " 'tobacco': 0.3359}\n",
      "46 Educational Standards\n",
      "{'accredit': 0.0342,\n",
      " 'adult': 0.0345,\n",
      " 'educ': 0.3221,\n",
      " 'institut': 0.062,\n",
      " 'profession': 0.0363,\n",
      " 'program': 0.0876,\n",
      " 'school': 0.0446,\n",
      " 'standard': 0.2492,\n",
      " 'student': 0.0695,\n",
      " 'vocat': 0.0599}\n",
      "47 Wildlife Extinction\n",
      "{'aquat': 0.0801,\n",
      " 'eagl': 0.041,\n",
      " 'endang': 0.055,\n",
      " 'extinct': 0.2295,\n",
      " 'fisheri': 0.0527,\n",
      " 'habitat': 0.047,\n",
      " 'owl': 0.0348,\n",
      " 'protect': 0.0391,\n",
      " 'speci': 0.1163,\n",
      " 'wildlif': 0.3045}\n",
      "48 Agoraphobia\n",
      "{'agoraphobia': 0.3711,\n",
      " 'cartoonist': 0.0492,\n",
      " 'charli': 0.0482,\n",
      " 'johnson': 0.0431,\n",
      " 'mental': 0.0647,\n",
      " 'peanut': 0.0828,\n",
      " 'schulz': 0.1879,\n",
      " 'she': 0.049,\n",
      " 'simmon': 0.0509,\n",
      " 'strip': 0.0531}\n",
      "49 Metabolism\n",
      "{'calori': 0.0461,\n",
      " 'data': 0.0318,\n",
      " 'diet': 0.0359,\n",
      " 'enzym': 0.0445,\n",
      " 'metabol': 0.5721,\n",
      " 'mpdl': 0.0492,\n",
      " 'nicotin': 0.0323,\n",
      " 'pathwai': 0.1311,\n",
      " 'wadden': 0.0285,\n",
      " 'weight': 0.0283}\n",
      "50 Health and Computer Terminals\n",
      "{'comput': 0.2039,\n",
      " 'health': 0.1645,\n",
      " 'injuri': 0.0398,\n",
      " 'newsdai': 0.0496,\n",
      " 'occup': 0.0512,\n",
      " 'rsi': 0.0568,\n",
      " 'screen': 0.0392,\n",
      " 'termin': 0.1784,\n",
      " 'vdt': 0.1634,\n",
      " 'workstat': 0.0532}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-retrival: 100%|\u001b[36m██████████\u001b[0m| 50/50 [00:05<00:00,  8.45it/s]\n",
      "100%|\u001b[31m██████████\u001b[0m| 1/1 [00:41<00:00, 41.34s/it]\n"
     ]
    }
   ],
   "source": [
    "k1 = 0.8\n",
    "b = 0.4\n",
    "\n",
    "top_PRD = [25]\n",
    "expanded_query_terms = [10]\n",
    "alpha = [0.7]\n",
    "mu = [750]\n",
    "\n",
    "parameters = list(itertools.product(top_PRD, expanded_query_terms, alpha, mu))\n",
    "\n",
    "for num_doc, num_q, alpha, mu in tqdm(parameters, colour='red'):\n",
    "    run_RM3(num_doc, num_q, alpha, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165abd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
