{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocchio True Relevance Feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rocchio Query Expansion using True Relevance Feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f414d5d3b30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import lucene\n",
    "from java.io import File\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.util import BytesRefIterator\n",
    "from org.apache.lucene.index import DirectoryReader, Term\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher, BooleanQuery, BooleanClause, TermQuery, BoostQuery\n",
    "from org.apache.lucene.search.similarities import BM25Similarity, LMJelinekMercerSimilarity, LMDirichletSimilarity\n",
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "indexPath = '../../TREC678/documents_index/'\n",
    "topicFilePath = '../../trec6.xml'\n",
    "# topicFilePath = '../../trec678-robust.xml'  # 50 queries\n",
    "\n",
    "tree = ET.parse(topicFilePath)\n",
    "topics = tree.getroot()\n",
    "\n",
    "\n",
    "index_path = indexPath\n",
    "directory = FSDirectory.open(File(index_path).toPath())\n",
    "indexReader = DirectoryReader.open(directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rocchio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average query langth and average documents length in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAME = 'CONTENTS'       # Lucene index field name\n",
    "\n",
    "# calculating avgdl for queries. Used in BM25_query().\n",
    "analyzer = EnglishAnalyzer()\n",
    "query_lens = []\n",
    "for topic in topics:\n",
    "    queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "    q = topic.find(queryKeywordsField).text.strip()\n",
    "    escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which\n",
    "    # EnglishAnalyzer was not able to parse\n",
    "    # without escaping those special characters\n",
    "    query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:]\n",
    "                   for term in query.toString().split()]\n",
    "    query_lens.append(len(query_terms))\n",
    "avgdl_query = sum(query_lens)/len(query_lens)\n",
    "\n",
    "# calculating avgdl for the corpus. Used in BM25_docVec().\n",
    "N = indexReader.numDocs()\n",
    "avgdl_collection = indexReader.getSumTotalTermFreq(FIELDNAME)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRelJudgeDict(qrelFilePath):\n",
    "    # returns a nested dictionary representation of trec678 qrel file\n",
    "    # for faster rel judgement checks during Rocchio query expansion.\n",
    "    # Nested Dict strcture is like,\n",
    "    # {qid1:{docid1:0/1,docid2:0/1,...}, qid2:{docid2:0/1,docid4:0/1,...},...}\n",
    "    relJudgeDict = {}\n",
    "    with open(qrelFilePath, 'r') as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            qid, docid, judgement = l[0], l[2], int(l[3])\n",
    "            if qid not in relJudgeDict:\n",
    "                relJudgeDict[qid] = {docid: judgement}\n",
    "            else:\n",
    "                relJudgeDict[qid][docid] = judgement\n",
    "    return relJudgeDict\n",
    "\n",
    "\n",
    "def isTrueRelevant(qid, docid, relJudgeDict):\n",
    "    # returns if the doc is True relevant, for the given query, according to the judgment file\n",
    "    if qid not in relJudgeDict:\n",
    "        return False\n",
    "    if docid not in relJudgeDict[qid]:\n",
    "        return False\n",
    "    if relJudgeDict[qid][docid] == 1:   # 1 -> Relevant TRF\n",
    "        return True\n",
    "    if relJudgeDict[qid][docid] == 0:\n",
    "        return False\n",
    "\n",
    "\n",
    "def isTrueNonRelevant(qid, docid, relJudgeDict):\n",
    "    # returns if the doc is NOT true relevant, for the given query, according to the judgment file\n",
    "    if qid not in relJudgeDict:\n",
    "        return False\n",
    "    if docid not in relJudgeDict[qid]:\n",
    "        return False\n",
    "    if relJudgeDict[qid][docid] == 0:   # 0 -> Non-relevant TRF\n",
    "        return True\n",
    "    if relJudgeDict[qid][docid] == 1:\n",
    "        return False\n",
    "\n",
    "\n",
    "# SET this to the relevance judgment file path\n",
    "qrelPath = '../../trec678_robust.qrel'\n",
    "# making a nested dictionary representation of judgement file for faster access\n",
    "relJudgeDict = makeRelJudgeDict(qrelPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in relJudgeDict:\n",
    "    count = 0\n",
    "    for values in relJudgeDict[keys].values():\n",
    "        if values == 1:\n",
    "            count += 1\n",
    "    print(f'keys:{keys}_reldocs:{count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_query(term, query_terms):\n",
    "    # returns TF-IDF weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    weight = (tf/D)*(math.log(N/(df+1)))\n",
    "    return weight\n",
    "\n",
    "\n",
    "def tf_idf_docVec(docVec, D):\n",
    "    # tf-idf weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(N/(df+1))\n",
    "        docVec[t] = (tf/D)*idf\n",
    "    return docVec\n",
    "\n",
    "\n",
    "def BM25_query(term, query_terms, k1=0.8, b=0.4):\n",
    "    # returns Okapi BM25 weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "    weight = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_query))))*idf\n",
    "    return weight\n",
    "\n",
    "\n",
    "def BM25_docVec(docVec, D, k1=0.8, b=0.4):\n",
    "    # Okapi BM25 weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "        docVec[t] = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_collection))))*idf\n",
    "    \n",
    "    return docVec\n",
    "\n",
    "\n",
    "def getDocumentVector(luceneDocid, weightScheme):\n",
    "    # returns document vector in dictionary form with tf-idf weights\n",
    "    \n",
    "    docVec = {}                     \n",
    "    \n",
    "    D = 0                           # doc length, i.e., total no. of tokens in the doc\n",
    "    terms = indexReader.getTermVector(luceneDocid, FIELDNAME)\n",
    "    iterator = terms.iterator()\n",
    "    for term in BytesRefIterator.cast_(iterator):\n",
    "        t = term.utf8ToString()\n",
    "        tf = iterator.totalTermFreq()                           # termFreq of term,t\n",
    "        df = indexReader.docFreq(Term(FIELDNAME, t))            # docFreq of term,t\n",
    "        D += tf\n",
    "        docVec[t] = [tf,df]\n",
    "        \n",
    "    if weightScheme == 'TFIDF':\n",
    "        docVec = tf_idf_docVec(docVec, D)\n",
    "    elif weightScheme == 'BM25':\n",
    "        docVec = BM25_docVec(docVec, D)\n",
    "\n",
    "    \n",
    "    docVec = {key: value/sum(docVec.values()) for key, value in docVec.items()}\n",
    "    \n",
    "    return docVec\n",
    "\n",
    "\n",
    "def rocchio_TRF(query, qid, top_k_docs, searcher, N, alpha, beta, gamma, weightScheme):\n",
    "    \"\"\"Implements Rocchio's relevance feedback and returns a modified query\n",
    "\n",
    "    Args:\n",
    "        query (org.apache.lucene.search.Query): lucene parsed version of the initial/original query\n",
    "        top_k_docs (lucene._lucene.JArray_object): scoreDocs returned after performing search with top k results\n",
    "        N (int): number of terms to be in the returned modified query\n",
    "        alpha (float): weight for original query\n",
    "        beta (float): weight for positive feedback\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "\n",
    "    Returns:\n",
    "        list: expanded/modified query list of string query terms\n",
    "    \"\"\"\n",
    "    \n",
    "    # processing JQuery object to extract query terms in form of a list\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:] for term in query.toString().split()]\n",
    "    \n",
    "    # creating query vector Q0\n",
    "    Q0_vector = {}\n",
    "    for term in query_terms:\n",
    "        if weightScheme == 'TFIDF':\n",
    "            Q0_vector[term] = tf_idf_query(term, query_terms)\n",
    "        elif weightScheme == 'BM25':\n",
    "            Q0_vector[term] = BM25_query(term, query_terms)\n",
    "\n",
    "    Q0_vector = {key: value/sum(Q0_vector.values()) for key, value in Q0_vector.items()}\n",
    "    \n",
    "    # Rel for Relevant, NRel for Non-relevant\n",
    "    sumRelDocsVector, sumNRelDocsVector = {}, {}\n",
    "    numRel, numNRel = 0, 0\n",
    "    for scoreDoc in top_k_docs:\n",
    "\n",
    "        doc = searcher.doc(scoreDoc.doc)\n",
    "        docVec = getDocumentVector(scoreDoc.doc, weightScheme)\n",
    "        if isTrueRelevant(qid, doc.get('ID'), relJudgeDict):\n",
    "            \n",
    "            numRel += 1\n",
    "            # vector addition of sumRelDocsVector and docVec\n",
    "            sumRelDocsVector = {term: sumRelDocsVector.get(term, 0) + docVec.get(term, 0) for term in set(sumRelDocsVector) | set(docVec)}\n",
    "        if isTrueNonRelevant(qid, doc.get('ID'), relJudgeDict):\n",
    "            numNRel += 1\n",
    "            # vector addition of sumNRelDocsVector and docVec\n",
    "            sumNRelDocsVector = {term: sumNRelDocsVector.get(term, 0) + docVec.get(term, 0) for term in set(sumNRelDocsVector) | set(docVec)}\n",
    "    if numRel == 0:\n",
    "        print(f'rel_vec_{sumRelDocsVector}')\n",
    "        # print(f'Nrel_vec_{sumNRelDocsVector}')\n",
    "\n",
    "    # normlaized Relevant Docs Vector\n",
    "    r = {term: sumRelDocsVector[term]/numRel for term in sumRelDocsVector}\n",
    "    # normlaized Non-Relevant Docs Vector\n",
    "    nr = {term: sumNRelDocsVector[term]/numNRel for term in sumNRelDocsVector}\n",
    "\n",
    "    # final Rocchio formula for Qm \n",
    "    # expanded_query = [[term, alpha*Q0_vector.get(term, 0) + beta*r.get(term, 0) - gamma*nr.get(term, 0)] for term in set(Q0_vector) | set(r) | set(nr)]\n",
    "    expanded_query = [[term, alpha*Q0_vector.get(term, 0) + beta*r.get(term, 0) - gamma*nr.get(term, 0)] for term in set(Q0_vector) | set(r)]\n",
    "\n",
    "    \n",
    "    expanded_query.sort(key = lambda x: x[1], reverse=True)   # sorted (descending) the expanded query list as per term scores\n",
    "    Qm_with_scores = expanded_query[:int(N)]     # selecting top N expanded query terms\n",
    "    \n",
    "    # weighting expanded query terms\n",
    "    booleanQuery = BooleanQuery.Builder()\n",
    "    # print(Qm_with_scores)\n",
    "    # print(f'Num_rel_{numRel}')\n",
    "    # print(f'NN_rel_{numNRel}')\n",
    "    for item in Qm_with_scores:\n",
    "        # if item[1] >= 0:\n",
    "        t = Term(FIELDNAME, item[0])\n",
    "        tq = TermQuery(t)\n",
    "        boostedTermQuery = BoostQuery(tq, item[1])\n",
    "        BooleanQuery.setMaxClauseCount(4096)\n",
    "        booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "    modifiedQuery = booleanQuery.build()\n",
    "    \n",
    "    return modifiedQuery   # modified query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMJM + Rocchio Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmjm_rocchio(numPRD, N, alpha, beta, gamma, weightScheme='TFIDF'):\n",
    "    \"\"\" Performs LMJM search with Rocchio pseudo relevance feedback \n",
    "        on a set of queries and output the result in a file\n",
    "\n",
    "    Args:\n",
    "        numPRD: no. of pseudo relevant docs\n",
    "        N: no. of expansion terms\n",
    "        alpha, beta: Rocchio model parameters\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "     \n",
    "    \n",
    "    model = 'lmjm'\n",
    "    LAMBDA = 0.4   # LM-JM baseline lambda parameter\n",
    "    similarityModel = LMJelinekMercerSimilarity(LAMBDA)\n",
    "\n",
    "#     k1 = 0.8\n",
    "#     b = 0.4\n",
    "#     similarityModel = BM25Similarity(k1,b)\n",
    "\n",
    "    # change result file path below\n",
    "    if weightScheme == 'BM25' or weightScheme == 'TFIDF':\n",
    "        rocchioOutputPath = f\"./Rocchio_output/TRF/{weightScheme}_with_gamma/TREC6_LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_gamma={gamma}_{weightScheme}.res\"\n",
    "    else:\n",
    "        print('Warning: weightScheme entered not a valid parameter value. Taking default weightScheme: TFIDF')\n",
    "        weightScheme = 'TFIDF'\n",
    "        rocchioOutputPath = f\"./Rocchio_output/TRF/{weightScheme}_with_gamma/TREC6_LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_gamma={gamma}_{weightScheme}.res\"\n",
    "    \n",
    "    f = open(rocchioOutputPath, 'w')\n",
    "\n",
    "    # setting up the searcher\n",
    "    analyzer = EnglishAnalyzer()    # used same analyzer as indexer\n",
    "#     index_path = './index/'\n",
    "    index = index_path\n",
    "    directory = FSDirectory.open(File(index_path).toPath())\n",
    "    searcher = IndexSearcher(DirectoryReader.open(directory))\n",
    "    # setting the similarity model\n",
    "    searcher.setSimilarity(similarityModel)\n",
    "\n",
    "    # print('\\nRetrieving ...')\n",
    "\n",
    "    # search on 50 queries from the topic file 'trec6.xml'\n",
    "    for topic in topics:\n",
    "        qidField = 'num'\n",
    "        queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "\n",
    "        qid = topic.find(qidField).text.strip()\n",
    "        q = topic.find(queryKeywordsField).text.strip()\n",
    "\n",
    "        escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which \n",
    "                                                                    # EnglishAnalyzer was not able to parse\n",
    "                                                                    # without escaping those special characters\n",
    "        query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "\n",
    "        # print(f'Rocchio {weightScheme}, numPRD = {numPRD}, N = {N}, alpha = {alpha}, beta = {beta}, gamma = {gamma} ; qid = {qid}, retrieving & writing ...', end=' ')\n",
    "\n",
    "        # getting the top pseudo relevant docs using the searcher\n",
    "        scoreDocs = searcher.search(query, numPRD).scoreDocs\n",
    "\n",
    "        # Rocchio expanded query retrieval\n",
    "        modified_query = rocchio_TRF(query, qid, top_k_docs=scoreDocs, searcher=searcher,  N=N, alpha=alpha, beta=beta, gamma=gamma, weightScheme=weightScheme)\n",
    "\n",
    "        # getting the top k search results using the searcher\n",
    "        k = 1000\n",
    "        scoreDocs = searcher.search(modified_query, k).scoreDocs\n",
    "\n",
    "        # writing all k doc results in a .res file in TREC format\n",
    "        rank = 0\n",
    "        results = ''\n",
    "        for scoreDoc in scoreDocs:\n",
    "            rank += 1\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            # f.write(f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\")\n",
    "            results += f\"{qid}\\tQ0\\t{doc.get('ID')}\\t{rank}\\t{scoreDoc.score}\\tlmjm_{LAMBDA}-rocchio_{alpha}_{beta}_{gamma}\\n\"\n",
    "        \n",
    "        f.write(results)\n",
    "\n",
    "        # print('complete!')\n",
    "\n",
    "    f.close()\n",
    "    # print('Search completed! Search results exported to a .res file in the current directory.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding max MAP for LMJM+Rocchio-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n",
      "rel_vec_{}\n"
     ]
    }
   ],
   "source": [
    "numPRD = 35\n",
    "N = 3\n",
    "alpha = 1\n",
    "for beta in [20]:\n",
    "    for gamma in [1]:\n",
    "\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='BM25')\n",
    "        lmjm_rocchio(numPRD=numPRD, N=N, alpha=alpha, beta=beta,gamma=gamma, weightScheme='TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# alphas = [i/100 for i in range(25,201,25)]\n",
    "# betas = [i/100 for i in range(25,201,25)]\n",
    "\n",
    "# for numTRD in tqdm(range(10,31,5)):\n",
    "#     for N in tqdm(range(50,121,10)):\n",
    "#         for alpha in tqdm(alphas):\n",
    "#             for beta in tqdm(betas):\n",
    "#                 lmjm_rocchio(numPRD=numTRD, N=N, alpha=alpha, beta=beta, gamma=gamma, weightScheme='TFIDF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest MAP value and corresponding params\n",
    "# LMJM with Rocchio TFIDF\n",
    "# [35, 115, 1.0, 20.0, 0.2834]\n",
    "# max MAP = 0.2834, for numPRD = 35, N = 115, alpha = 1.0, beta = 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 +  Rocchio Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_rocchio(numPRD, N, alpha, beta, weightScheme='TFIDF'):\n",
    "    \"\"\" Performs bm25 search with Rocchio pseudo relevance feedback \n",
    "        on a set of queries and output the result in a file\n",
    "\n",
    "    Args:\n",
    "        numPRD: no. of pseudo relevant docs\n",
    "        N: no. of expansion terms\n",
    "        alpha, beta: Rocchio model parameters\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "     \n",
    "    \n",
    "    model = 'bm25'\n",
    "#     LAMBDA = 0.4   # LM-JM baseline lambda parameter\n",
    "#     similarityModel = LMJelinekMercerSimilarity(LAMBDA)\n",
    "\n",
    "    k1 = 0.8\n",
    "    b = 0.4\n",
    "    similarityModel = BM25Similarity(k1,b)\n",
    "\n",
    "    # change result file path below\n",
    "    if weightScheme == 'BM25' or weightScheme == 'TFIDF':\n",
    "        rocchioOutputPath = f\"./RESFILE/PRF/{weightScheme}/TREC6_BM25_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    else:\n",
    "        print('Warning: weightScheme entered not a valid parameter value. Taking default weightScheme: TFIDF')\n",
    "        weightScheme = 'TFIDF'\n",
    "        rocchioOutputPath = f\"./RESFILE/PRF/{weightScheme}/TREC6_BM25_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    \n",
    "    f = open(rocchioOutputPath, 'w')\n",
    "\n",
    "    # setting up the searcher\n",
    "    analyzer = EnglishAnalyzer()    # used same analyzer as indexer\n",
    "#     index_path = './index/'\n",
    "    index = index_path\n",
    "    directory = FSDirectory.open(File(index_path).toPath())\n",
    "    searcher = IndexSearcher(DirectoryReader.open(directory))\n",
    "    # setting the similarity model\n",
    "    searcher.setSimilarity(similarityModel)\n",
    "\n",
    "    print('\\nRetrieving ...')\n",
    "\n",
    "    # search on 50 queries from the topic file 'trec6.xml'\n",
    "    for topic in topics:\n",
    "        qidField = 'num'\n",
    "        queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "\n",
    "        qid = topic.find(qidField).text.strip()\n",
    "        q = topic.find(queryKeywordsField).text.strip()\n",
    "\n",
    "        escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which \n",
    "                                                                    # EnglishAnalyzer was not able to parse\n",
    "                                                                    # without escaping those special characters\n",
    "        query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "\n",
    "        print(f'Rocchio {weightScheme}, numPRD = {numPRD}, N = {N}, alpha = {alpha}, beta = {beta}; qid = {qid}, retrieving & writing ...', end=' ')\n",
    "\n",
    "        # getting the top pseudo relevant docs using the searcher\n",
    "        scoreDocs = searcher.search(query, numPRD).scoreDocs\n",
    "\n",
    "        # Rocchio expanded query retrieval\n",
    "        modified_query = rocchio_PRF(query, scoreDocs, N=N, alpha=alpha, beta=beta, weightScheme=weightScheme)\n",
    "\n",
    "        # getting the top k search results using the searcher\n",
    "        k = 1000\n",
    "        scoreDocs = searcher.search(modified_query, k).scoreDocs\n",
    "\n",
    "        # writing all k doc results in a .res file in TREC format\n",
    "        rank = 0\n",
    "        results = ''\n",
    "        for scoreDoc in scoreDocs:\n",
    "            rank += 1\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            # f.write(f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\")\n",
    "            results += f\"{qid}\\tQ0\\t{doc.get('ID')}\\t{rank}\\t{scoreDoc.score}\\tBM25_{k1}-{b}-rocchio_{alpha}_{beta}\\n\"\n",
    "        \n",
    "        f.write(results)\n",
    "\n",
    "        print('complete!')\n",
    "\n",
    "    f.close()\n",
    "    print('Search completed! Search results exported to a .res file in the current directory.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPRD = 20\n",
    "N = 70\n",
    "alpha = 1\n",
    "beta = 30\n",
    "\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='BM25')\n",
    "bm25_rocchio(numPRD=numPRD, N=N, alpha=alpha, beta=beta, weightScheme='TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [10,20,30,40,50]:\n",
    "    for t in [10,20,30,40,50,60,70,80]:\n",
    "        bm25_rocchio(numPRD=d, N=t, alpha=alpha, beta=beta, weightScheme='TFIDF')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
