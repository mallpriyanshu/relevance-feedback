{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocchio & Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f58b2991bf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "from org.apache.lucene.search.similarities import LMJelinekMercerSimilarity\n",
    "from org.apache.lucene.search.similarities import LMDirichletSimilarity\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from java.io import File\n",
    "\n",
    "from org.apache.lucene.search import BooleanQuery\n",
    "from org.apache.lucene.search import BooleanClause\n",
    "from org.apache.lucene.search import TermQuery\n",
    "from org.apache.lucene.search import BoostQuery\n",
    "from org.apache.lucene.index import Term\n",
    "from org.apache.lucene.util import BytesRefIterator\n",
    "# run this again if VM is not initialized already\n",
    "lucene.initVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_name = 'trec6'\n",
    "topicFilePath = f\"../../{q_name}.xml\"  # 50 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(topicFilePath)\n",
    "topics = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = '../../TREC678/documents_index/'\n",
    "directory = FSDirectory.open(File(index_path).toPath())\n",
    "indexReader = DirectoryReader.open(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "FIELDNAME = 'CONTENTS'       # Lucene index field name\n",
    "\n",
    "\n",
    "# calculating avgdl for queries. Used in BM25_query().\n",
    "analyzer = EnglishAnalyzer()\n",
    "query_lens = []\n",
    "for topic in topics:\n",
    "    queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "    q = topic.find(queryKeywordsField).text.strip()\n",
    "    \n",
    "    escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which\n",
    "    # EnglishAnalyzer was not able to parse\n",
    "    # without escaping those special characters\n",
    "    query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:]\n",
    "                   for term in query.toString().split()]\n",
    "    query_lens.append(len(query_terms))\n",
    "avgdl_query = sum(query_lens)/len(query_lens)\n",
    "\n",
    "# calculating avgdl for the corpus. Used in BM25_docVec().\n",
    "N = indexReader.numDocs()\n",
    "avgdl_collection = indexReader.getSumTotalTermFreq(FIELDNAME)/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188624297\n"
     ]
    }
   ],
   "source": [
    "print(indexReader.getSumTotalTermFreq(FIELDNAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_query(term, query_terms):\n",
    "    # returns TF-IDF weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    weight = (tf/D)*(math.log(N/(df+1)))\n",
    "    return weight\n",
    "\n",
    "def tf_idf_docVec(docVec, D):\n",
    "    # tf-idf weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(N/(df+1))\n",
    "        docVec[t] = (tf/D)*idf\n",
    "    return docVec\n",
    "\n",
    "def BM25_query(term, query_terms, k1=0.8, b=0.4):\n",
    "    # returns Okapi BM25 weight for the given term in query\n",
    "    D = len(query_terms)\n",
    "    N = indexReader.numDocs()\n",
    "    tf = query_terms.count(term)\n",
    "    df = indexReader.docFreq(Term(FIELDNAME, term))\n",
    "    idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "    weight = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_query))))*idf\n",
    "    return weight\n",
    "\n",
    "def BM25_docVec(docVec, D, k1=0.8, b=0.4):\n",
    "    # Okapi BM25 weight calculation for all the terms in the document vector\n",
    "    N = indexReader.numDocs()       # no. of total docs in the corpus\n",
    "    for t in docVec:\n",
    "        tf = docVec[t][0]\n",
    "        df = docVec[t][1]\n",
    "        idf = math.log(1+((N-df+0.5)/(df+0.5)))\n",
    "        docVec[t] = ((tf*(1+k1))/(tf+k1*((1-b)+(b*D/avgdl_collection))))*idf    \n",
    "    return docVec\n",
    "\n",
    "def getDocumentVector(luceneDocid, weightScheme):\n",
    "    # returns document vector in dictionary form with tf-idf weights\n",
    "    docVec = {}                     # doc vector, which will have terms as keys and \n",
    "                                    # its tf-idf weight in the doc as values\n",
    "    \n",
    "    D = 0                           # doc length, i.e., total no. of tokens in the doc\n",
    "    terms = indexReader.getTermVector(luceneDocid, FIELDNAME)\n",
    "    iterator = terms.iterator()\n",
    "    for term in BytesRefIterator.cast_(iterator):\n",
    "        t = term.utf8ToString()\n",
    "        tf = iterator.totalTermFreq()    # termFreq of term,t\n",
    "        df = indexReader.docFreq(Term(FIELDNAME, t))    # docFreq of term,t\n",
    "        D += tf\n",
    "        docVec[t] = [tf,df]\n",
    "        \n",
    "    if weightScheme == 'TFIDF':\n",
    "        docVec = tf_idf_docVec(docVec, D)\n",
    "    elif weightScheme == 'BM25':\n",
    "        docVec = BM25_docVec(docVec, D)\n",
    "    \n",
    "    return docVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_PRF(query, top_k_docs, N, alpha, beta, weightScheme):\n",
    "    \"\"\"Implements Rocchio's relevance feedback and returns a modified query\n",
    "\n",
    "    Args:\n",
    "        query (org.apache.lucene.search.Query): lucene parsed version of the initial/original query\n",
    "        top_k_docs (lucene._lucene.JArray_object): scoreDocs returned after performing search with top k results\n",
    "        N (int): number of terms to be in the returned modified query\n",
    "        alpha (float): weight for original query\n",
    "        beta (float): weight for positive feedback\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "\n",
    "    Returns:\n",
    "        list: expanded/modified query list of string query terms\n",
    "    \"\"\"\n",
    "\n",
    "    # processing JQuery object to extract query terms in form of a list\n",
    "    query_terms = [term.strip()[len(FIELDNAME)+1:]\n",
    "                   for term in query.toString().split()]\n",
    "\n",
    "    # creating query vector Q0\n",
    "    Q0_vector = {}\n",
    "    for term in query_terms:\n",
    "        if weightScheme == 'TFIDF':\n",
    "            Q0_vector[term] = tf_idf_query(term, query_terms)\n",
    "        elif weightScheme == 'BM25':\n",
    "            Q0_vector[term] = BM25_query(term, query_terms)\n",
    "\n",
    "    sumRelDocsVector = {}     # Rel for Relevant, NRel for Non-relevant\n",
    "    numRel = 0\n",
    "    for scoreDoc in top_k_docs:\n",
    "        docVec = getDocumentVector(scoreDoc.doc, weightScheme)\n",
    "        numRel += 1\n",
    "        # vector addition of sumRelDocsVector and docVec\n",
    "        for term in docVec:\n",
    "            if term in sumRelDocsVector:\n",
    "                sumRelDocsVector[term] += docVec[term]\n",
    "            else:\n",
    "                sumRelDocsVector[term] = docVec[term]\n",
    "\n",
    "    # normlaized Relevant Docs Vector\n",
    "    r = {term: sumRelDocsVector[term]/numRel for term in sumRelDocsVector}\n",
    "\n",
    "    # final Rocchio formula for Qm\n",
    "    expanded_query = [\n",
    "        [term, alpha*Q0_vector.get(term, 0) + beta*r.get(term, 0)] for term in set(Q0_vector) | set(r)]\n",
    "\n",
    "    # sorted (descending) the expanded query list as per term scores\n",
    "    expanded_query.sort(key=lambda x: x[1], reverse=True)\n",
    "    # selecting top N expanded query terms\n",
    "    Qm_with_scores = expanded_query[:int(N)]\n",
    "\n",
    "    # weighting expanded query terms\n",
    "    booleanQuery = BooleanQuery.Builder()\n",
    "    for item in Qm_with_scores:\n",
    "        t = Term(FIELDNAME, item[0])\n",
    "        tq = TermQuery(t)\n",
    "        boostedTermQuery = BoostQuery(tq, item[1])\n",
    "        BooleanQuery.setMaxClauseCount(4096)\n",
    "        booleanQuery.add(boostedTermQuery, BooleanClause.Occur.SHOULD)\n",
    "    modifiedQuery = booleanQuery.build()\n",
    "\n",
    "    return modifiedQuery   # modified query\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 + Rocchio Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_rocchio(numPRD, N, alpha, beta, weightScheme='TFIDF'):\n",
    "    \"\"\" Performs bm25 search with Rocchio pseudo relevance feedback \n",
    "        on a set of queries and output the result in a file\n",
    "\n",
    "    Args:\n",
    "        numPRD: no. of pseudo relevant docs\n",
    "        N: no. of expansion terms\n",
    "        alpha, beta: Rocchio model parameters\n",
    "        weightScheme (string): TFIDF or BM25 for term weighting\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    model = 'bm25'\n",
    "#     LAMBDA = 0.4   # LM-JM baseline lambda parameter\n",
    "#     similarityModel = LMJelinekMercerSimilarity(LAMBDA)\n",
    "\n",
    "    k1 = 0.8\n",
    "    b = 0.4\n",
    "    similarityModel = BM25Similarity(k1, b)\n",
    "\n",
    "    # change result file path below\n",
    "    if weightScheme == 'BM25' or weightScheme == 'TFIDF':\n",
    "        rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/{q_name}/{q_name}_BM25_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    else:\n",
    "        print('Warning: weightScheme entered not a valid parameter value. Taking default weightScheme: TFIDF')\n",
    "        weightScheme = 'TFIDF'\n",
    "        rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/{q_name}/{q_name}_BM25_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "\n",
    "    f = open(rocchioOutputPath, 'w')\n",
    "\n",
    "    # setting up the searcher\n",
    "    analyzer = EnglishAnalyzer()    # used same analyzer as indexer\n",
    "#     index_path = './index/'\n",
    "    index = index_path\n",
    "    directory = FSDirectory.open(File(index_path).toPath())\n",
    "    searcher = IndexSearcher(DirectoryReader.open(directory))\n",
    "    # setting the similarity model\n",
    "    searcher.setSimilarity(similarityModel)\n",
    "\n",
    "    # print('\\nRetrieving ...')\n",
    "\n",
    "    # search on 50 queries from the topic file 'trec6.xml'\n",
    "    for topic in topics:\n",
    "        qidField = 'num'\n",
    "        queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "\n",
    "        qid = topic.find(qidField).text.strip()\n",
    "        q = topic.find(queryKeywordsField).text.strip()\n",
    "\n",
    "        escaped_q = QueryParser(FIELDNAME, analyzer).escape(\n",
    "            q)      # a few titles had '/' in them which\n",
    "        # EnglishAnalyzer was not able to parse\n",
    "        # without escaping those special characters\n",
    "        query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "\n",
    "        # print(f'Rocchio {weightScheme}, numPRD = {numPRD}, N = {N}, alpha = {alpha}, beta = {beta}; qid = {qid}, retrieving & writing ...', end=' ')\n",
    "\n",
    "        # getting the top pseudo relevant docs using the searcher\n",
    "        scoreDocs = searcher.search(query, numPRD).scoreDocs\n",
    "\n",
    "        # Rocchio expanded query retrieval\n",
    "        modified_query = rocchio_PRF(\n",
    "            query, scoreDocs, N=N, alpha=alpha, beta=beta, weightScheme=weightScheme)\n",
    "\n",
    "        # getting the top k search results using the searcher\n",
    "        k = 1000\n",
    "        scoreDocs = searcher.search(modified_query, k).scoreDocs\n",
    "\n",
    "        # writing all k doc results in a .res file in TREC format\n",
    "        rank = 0\n",
    "        results = ''\n",
    "        for scoreDoc in scoreDocs:\n",
    "            rank += 1\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            # f.write(f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\")\n",
    "            results += f\"{qid}\\tQ0\\t{doc.get('ID')}\\t{rank}\\t{scoreDoc.score}\\tBM25_{k1}-{b}-rocchio_{alpha}_{beta}\\n\"\n",
    "\n",
    "        f.write(results)\n",
    "\n",
    "        # print('complete!')\n",
    "\n",
    "    f.close()\n",
    "    # print('Search completed! Search results exported to a .res file in the current directory.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[31m██████████\u001b[0m| 1/1 [01:00<00:00, 60.61s/it]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "numPRD = [11]\n",
    "N = [45]\n",
    "alpha = [1]\n",
    "beta = [22]\n",
    "\n",
    "parameters = list(itertools.product(numPRD, N, alpha, beta))\n",
    "for numPRD, N, alpha, beta in tqdm(parameters, colour='red'):\n",
    "\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='BM25')\n",
    "    bm25_rocchio(numPRD=numPRD, N=N, alpha=alpha, beta=beta, weightScheme='BM25')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMJM + Rocchio Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lmjm_rocchio(numPRD, N, alpha, beta, weightScheme='TFIDF'):\n",
    "#     \"\"\" Performs LMJM search with Rocchio pseudo relevance feedback \n",
    "#         on a set of queries and output the result in a file\n",
    "\n",
    "#     Args:\n",
    "#         numPRD: no. of pseudo relevant docs\n",
    "#         N: no. of expansion terms\n",
    "#         alpha, beta: Rocchio model parameters\n",
    "#         weightScheme (string): TFIDF or BM25 for term weighting\n",
    "        \n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "     \n",
    "    \n",
    "#     model = 'lmjm'\n",
    "#     LAMBDA = 0.4   # LM-JM baseline lambda parameter\n",
    "#     similarityModel = LMJelinekMercerSimilarity(LAMBDA)\n",
    "\n",
    "#     # k1 = 0.8\n",
    "#     # b = 0.4\n",
    "#     # similarityModel = BM25Similarity(k1,b)\n",
    "\n",
    "#     # change result file path below\n",
    "#     if weightScheme == 'BM25' or weightScheme == 'TFIDF':\n",
    "#         rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/{q_name}_LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "#     else:\n",
    "#         print('Warning: weightScheme entered not a valid parameter value. Taking default weightScheme: TFIDF')\n",
    "#         weightScheme = 'TFIDF'\n",
    "#         rocchioOutputPath = f\"./Rocchio_output/{weightScheme}/{q_name}_LMJM_Rocchio_numPRD={numPRD}_N={N}_alpha={alpha}_beta={beta}_{weightScheme}.res\"\n",
    "    \n",
    "#     f = open(rocchioOutputPath, 'w')\n",
    "\n",
    "#     # setting up the searcher\n",
    "#     analyzer = EnglishAnalyzer()    # used same analyzer as indexer\n",
    "#     index_path = '../../TREC678/documents_index/'\n",
    "#     directory = FSDirectory.open(File(index_path).toPath())\n",
    "#     searcher = IndexSearcher(DirectoryReader.open(directory))\n",
    "#     # setting the similarity model\n",
    "#     searcher.setSimilarity(similarityModel)\n",
    "\n",
    "#     print('\\nRetrieving ...')\n",
    "\n",
    "#     # search on 50 queries from the topic file 'trec6.xml'\n",
    "#     for topic in topics:\n",
    "#         qidField = 'num'\n",
    "#         queryKeywordsField = 'title'     # other fields are 'desc'and 'narr'\n",
    "\n",
    "#         qid = topic.find(qidField).text.strip()\n",
    "#         q = topic.find(queryKeywordsField).text.strip()\n",
    "\n",
    "#         escaped_q = QueryParser(FIELDNAME, analyzer).escape(q)      # a few titles had '/' in them which \n",
    "#                                                                     # EnglishAnalyzer was not able to parse\n",
    "#                                                                     # without escaping those special characters\n",
    "#         query = QueryParser(FIELDNAME, analyzer).parse(escaped_q)\n",
    "\n",
    "#         print(f'Rocchio {weightScheme}, numPRD = {numPRD}, N = {N}, alpha = {alpha}, beta = {beta}; qid = {qid}, retrieving & writing ...', end=' ')\n",
    "\n",
    "#         # getting the top pseudo relevant docs using the searcher\n",
    "#         scoreDocs = searcher.search(query, numPRD).scoreDocs\n",
    "\n",
    "#         # Rocchio expanded query retrieval\n",
    "#         modified_query = rocchio_PRF(query, scoreDocs, N=N, alpha=alpha, beta=beta, weightScheme=weightScheme)\n",
    "\n",
    "#         # getting the top k search results using the searcher\n",
    "#         k = 1000\n",
    "#         scoreDocs = searcher.search(modified_query, k).scoreDocs\n",
    "\n",
    "#         # writing all k doc results in a .res file in TREC format\n",
    "#         rank = 0\n",
    "#         results = ''\n",
    "#         for scoreDoc in scoreDocs:\n",
    "#             rank += 1\n",
    "#             doc = searcher.doc(scoreDoc.doc)\n",
    "#             # f.write(f\"{qid}\\tQ0\\t{doc.get('DOCID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\")\n",
    "#             results += f\"{qid}\\tQ0\\t{doc.get('ID')}\\t{rank}\\t{scoreDoc.score}\\taman_lmjm_{LAMBDA}-rocchio_{alpha}_{beta}\\n\"\n",
    "        \n",
    "#         f.write(results)\n",
    "\n",
    "#         print('complete!')\n",
    "\n",
    "#     f.close()\n",
    "#     print('Search completed! Search results exported to a .res file in the current directory.\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding max MAP for LMJM+Rocchio-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numPRD = 11\n",
    "# N = 45\n",
    "\n",
    "# alpha = 1\n",
    "# beta = 30\n",
    "\n",
    "# lmjm_rocchio(numPRD=numPRD,N=N,alpha=alpha,beta=beta, weightScheme='TFIDF')\n",
    "# # lmjm_rocchio(numPRD=numPRD, N=N, alpha=alpha, beta=beta, weightScheme='TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest MAP value and corresponding params\n",
    "# LMJM with Rocchio TFIDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
